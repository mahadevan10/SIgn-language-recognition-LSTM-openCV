# ğŸ§  Action Detection with LSTM â€“ Real-Time Human Pose Classification

> Real-time human action detection using LSTM on Mediapipe pose landmarks. Trained on 8 action classes with high accuracy and evaluated using multilabel confusion matrices. Model deployed for gesture recognition applications.

---

## ğŸ“Œ Short Description

Real-time action detection using LSTM and Mediapipe pose landmarks. Trained on 8 classes with ~98% accuracy and validated using multilabel confusion matrix. Ideal for gesture and sign language recognition.

---

## Project Overview

This project implements a real-time action detection system using **LSTM neural networks**. It processes pose landmarks extracted using **Mediapipe** from webcam input and classifies them into one of **8 predefined gestures**.

---

## Model Architecture

```text
LSTM(64) â†’ LSTM(128) â†’ LSTM(64) â†’ Dense(64) â†’ Dense(32) â†’ Dense(8)
```

## ğŸ— Model Details

- **Loss Function**: `categorical_crossentropy`  
- **Optimizer**: `Adam` with learning rate 0.01  
- **Metrics**: Accuracy  
- **Epochs**: 80  
- **Parameters**: 203,624 total  

---

## ğŸ“Š Evaluation Results

- âœ… **Training Accuracy**: ~98.9%  
- âœ… **Validation Accuracy**: ~95%  
- âœ… **Metrics**: `multilabel_confusion_matrix` for per-class analysis  

**Example Confusion Matrix Output:**

[[61, 0],
[ 0,11]]

[[62, 1],
[ 1, 8]]



---

## ğŸ›  Tech Stack

- Python  
- TensorFlow / Keras  
- Mediapipe  
- NumPy  
- OpenCV  
- Jupyter Notebook  

---

## ğŸ¥ Demo

ğŸ“½ï¸ Real-time webcam gesture recognition  
â–¶ï¸ `Recording 2025-08-05 112324.mp4`

---

## ğŸ“ Files Included

- `Action Detection Refined.ipynb` â€“ Full code  
- `model.h5` â€“ Trained model  
- `README.md` â€“ This file  
- `.mp4` â€“ Sample prediction recording
- `image` â€“ Model Summary
- `image` â€“ Confusion Matrix


---

## ğŸ§ª How to Run

```bash
git clone https://github.com/yourusername/action-detection-lstm.git
cd action-detection-lstm
jupyter notebook


